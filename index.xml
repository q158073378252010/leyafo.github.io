<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Doing Right Things</title>
    <link>http://www.leyafo.com/</link>
    <description>Recent content on Doing Right Things</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>All rights reserved by Leyafo</copyright>
    <lastBuildDate>Wed, 02 May 2018 18:10:17 +0800</lastBuildDate>
    
	<atom:link href="http://www.leyafo.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>NSQ 简介</title>
      <link>http://www.leyafo.com/post/2018-05-02-introduce_nsq/</link>
      <pubDate>Wed, 02 May 2018 18:10:17 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2018-05-02-introduce_nsq/</guid>
      <description>在一般的 HTTP 后台系统中如果使用大量使用同步 API 调用一个长时间的任务时会拖慢整个系统的承载能力。在流量不大的情况下，我们可以把利用像 Redis 这样的缓存系统自行设计一个简单 producer / consumer 模式的消息队列。做好这个组件我们需要考虑到的问题有：
1.多个线程抢占一个资源时加锁的问题。
2.保证每个消息都能执行一次。
3.保证这个组件不会因为突发流量高峰而宕机。
要解决这三个问题并不容易，如果需要大规模的任务处理，横向扩展，分布式，预防单点故障等一系列需要解决的问题并不少。这时候选用一个久经考验的消息队列系统是非常好的选择。
NSQ 是一个实时消息推送平台。它具有分布式，水平扩展，低延时，防止单点故障等特性。与类似 RubbitMQ, ZeroMQ 等分布式队列一样，主要用于解决异步高并发消息的推送与处理。与其他分布式队列不同的是，NSQ 没有类似 brokers 的中间节点，无中心的特性可以让它无缝添加一个节点。
按组件分类，NSQ 主要可以分为三大块，分别是：
nsqd （核心组件）用于接收与分发消息，处理通信协议。
nsqlookupd 用于查找并定位多个 nsqd，管理多个 nsqd 之间的拓扑信息。它不负责处理任何数据的传输与处理。
producer / consumer 消息的生产与发送者，这是用户功能具体实现的地方。每当一个消息由生产者发送到整个 NSQ 网络中，会有一个对应 consumer 负责与 NSQ 通信并处理这个消息。
下图是这三个组件之间的拓扑关系：
nsqlookupd 用于连接 consumer 和 nsqd，它作的工作类似于寻址，帮助 nsqd 找到对应的 consumer 处理消息。
在这里有个地方非常值得注意，就是 producer 没有通过 nsqlookupd 去找对应的对应的 nsq 节点发送消息。而是直接通过一个 nsqd 发送，这么设计的原因是：
 producer 只要负责把消息投递出去，系统的并发处理压力全在 consumer 这一端。再多的 producer 发消息都不会影响 consumer 的运行效率。 如果 producer 通过 nsqlookupd 寻址找 nsqd，会产生鸡生蛋蛋生鸡的问题。 配置更简单，横向扩展要更容易。  更多详细情参见这里。</description>
    </item>
    
    <item>
      <title>一条网络请求背后经历了什么？</title>
      <link>http://www.leyafo.com/post/2018-04-21-a-net-reqest-track/</link>
      <pubDate>Sat, 21 Apr 2018 14:51:47 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2018-04-21-a-net-reqest-track/</guid>
      <description>下图是打开网页背后应用层发生的事情。大型的网站会比这个复杂的多（我也没做过，所以画不出更复杂的图:) ）。
中间涉及到的网络底层处理流程这张图没法全部描述出来，这又是另一个复杂的流程。下图是一个网络数据包到达另一个节点的详细流程，也是经典的 7 层 OSI 模型。上图几乎每一条实线的两边节点都会涉及以下流程。
我们最常用的协议是基于 TCP 的 HTTP 协议。TCP 的特点在于两端必须要建立可靠的连接才能进行通信。所以客户端会首先发起建立连接请求，服务端收到请求后并给予回应，客户端收到回应后再往服务端发送一条成功建立连接的回应，这时两边的 TCP 通道便成功建立起来发送数据。以下是三次握手的流程。
在上文我们说过，网络数据发送都是由一个个包组成的。那这包里的信息到底包含哪些东西呢？以下是一个网络数据包里面包含的内容。
一个数据包里面之所以会分为这么多的段，是因为 OSI 模型每一层都有它自己需要关注的数据段并处理。
在我们平常的使用网络的过程中，我们看起来好像只要知道对方的 IP 就能和对方进行通信。实际的网络传输过程中机器 MAC 地址是必不可少的，当我们把数据包送到一个 IP 地址所在的主机时，这个主机并不一定就是目的主机。需要靠路由去广播找到对应机器。以送快递为例，我们知道收件人的地址，但不知道收件人的姓名。我们可以把快递发到目的地，但无法到达收件人的手里。这也可以解释我们在家里的路由器后把一个 HTTP 服务器运行在我们的电脑上，我们在公司是无法直接访问到这台 HTTP 服务器的，是需要做一些类似内网穿透这样的措施才行。
MAC 地址的另外一个作用就是决定网络请求包发送的下一个目的地。在一个网络我们与其他机器通信并不一定是直接与另一个节点通信，而是会经过很多中间节点。这中间节点的路径由 ARP 协议决定，它靠广播来找到对应接收数据的节点。
当我们发送一个 HTTP 请求时，最后到达我们 listen 的 socket 时，我们只需要关心数据层里面的数据即可。以下是一个HTTP 请求的头部信息，也就是最终到达 socket 应用层的数据。
HTTP/1.1 302 Found Server: Tengine Date: Tue, 24 Apr 2018 02:00:40 GMT Content-Type: text/html Content-Length: 258 Connection: keep-alive Location: https://www.taobao.com/ Set-Cookie: thw=cn; Path=/; Domain=.taobao.com; Expires=Wed, 24-Apr-19 02:00:40 GMT; Strict-Transport-Security: max-age=31536000 在 HTTP 服务器里面需要做的就是解析这里面的数据，返回客户端想要的资源。</description>
    </item>
    
    <item>
      <title>HTTP API golang 的选择</title>
      <link>http://www.leyafo.com/post/2018-04-06-golang-writes-http-api/</link>
      <pubDate>Fri, 06 Apr 2018 16:16:58 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2018-04-06-golang-writes-http-api/</guid>
      <description>写一个 HTTP API 服务我们首先想到的就是找一个 Web framework 去实现。Framework 简单的来说就是设定一种代码运行的规范机制，所有业务逻辑相关的代码使用同一抽象的方式去运行。再提供一定的组合方式让代码的各个部件粘合起来，MVC 就是一种粘合方式。以前后端 HTML 模版的渲染做的就是 V(view) 这一层的东西，页面上用的数据 M(model) 这一层靠的是 C(controler) 在两者之间调度。不得不说 MVC 设计模式完美贴合了 web 开发，市面上所有号称 web framework 的东西都离不开 MVC 的身影，可见 Rails 在这方面开的先河还是非常优秀的。
现在微服务大行其道，前后端分离让后端可以专注于处理前后端数据交互，不用再关心前端的数据渲染, 打包，压缩，部署，测试，以及页面模版等一系列问题。以上要做的这些工作加上后端数据库相关的那一坨 sql 处理代码，以及各种缓存的处理让 Web framework 变得极其复杂。上面这些东西一般的语言实现起来都不会少于 10 万行的代码量。我们做一个项目写的业务逻辑超过十万行都是非常可观的代码量，维护起来不是那么容易的事情。
好马配好鞍，杀鸡别用牛刀。在前端技术爆发的年代，后端的 MVC 终于可以彻底把 View 层的重担卸载下来。当我们完全不用再考虑 View 层面里面的任何东西时，Model 层的重担我们也可以暂时放下，只需要关心 HTTP 的 request 和 response 即可。这样 Web 后端要处理的东西几乎没剩下多少，只需要找个地方可以装下 request 和 response 处理的地方，其他我们只需要再处理下 router 即可。在这种应用场景下，找不到任需要依赖大型 Framework 的理由。在额外的负担全部去掉的情况下，我们可以让后端的代码变得极其简洁，做到让任何人的能快速上手维护，尤其是使用 golang 可以不过多的依赖外部的 library。这里可以看我是如何实现的最小号的 HTTP API services。另外可以看我这篇文章是如何实现简单的 Model 层。
在项目里面我们平常会需要使用配置文件来设置一些参数让程序运行，比如连接参数， 生产环境与其他环境的不同运行参数等。常见的配置文件有 YML, Toml, xml, json, ini 等，这些配置文件本质上就是解析 key value 参数。与以往不同的是，在 golang 里面我们可以植入 Lua 来作为配置文件。Lua 这门语言本身就是植入式到宿主语言用的，它的虚拟机很小，只有 2K。在上世纪 8 ~ 90 年代时那时 C/C++ 这些系统级的静态编程语言大行其道。我们看到的很多古老的项目如 Vim, Emacs 它内部都附带了一个脚本语言作为插件拓展程序的功能，并且配置文件也是使用这个脚本语言。我甚至有时在想，如果那时候 Lua 流行起来，像 javascript 或 vimscript 这样的脚本语言真没有发明的必要。作为专门的植入式语言 Lua 比他们优秀太多了。</description>
    </item>
    
    <item>
      <title>在家乡一些行之有效的策略</title>
      <link>http://www.leyafo.com/post/2018-02-26-hometowns-strategy/</link>
      <pubDate>Mon, 26 Feb 2018 15:55:09 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2018-02-26-hometowns-strategy/</guid>
      <description>比贫穷更可怕的事情是缺乏见识、缺乏爱、缺乏规矩。没有钱，有一辈子的机会能够获得，而缺乏这三样东西，后天再获得的难度就非常大了，而它们的缺乏其实和贫穷没有必然联系。
－吴军
 中国经过改革开放这 40 年的发展，已经发生了翻天覆地的变化。我们父辈从吃不饱，穿不暖的年代发展到现在物质过剩这中间的 40 年在历史上是极短的。随之带来的问题就是两代人之间观念的变化越来越大，代沟也无可避免的产生了。人的观念一旦定型非常难以扭转，这种上下辈之间产生的代沟最好的解决方式不是改变，而是要选择与代沟共存。人和人之间生活环境的差别是非常大的，如果你多走一些地方旅行会深切体会到这种差异，有时甚至会感受到我们这些巨大差异的人生活在同一个地球是件很神奇的事情。
一、在任何社会都要入乡问俗、入乡随俗 这里的“俗”是指习俗，生活习惯，甚至还包括一些看起来无关紧要的仪式。我们无法只使用一种思维方式去解决所有问题，一种生活习惯也无法适应所有的社会。适应不同社会的最好方式就要像变色龙一样，随着身边的环境去调整自身的处事方式。这种调整不仅要做到入乡随俗，还要事先入乡问俗，这样才能避免一些让自己和他人都不快的尴尬局面。
二、永远不要轻易谈钱 吉姆罗杰斯说过：“永远不要问别人赚多少钱以及某样东西值多少钱。不要告诉别人你的东西多少钱买的，不要跟人谈论你赚多少钱以及有多少身家。因为谈论这些事不但扎眼，而且缺乏教养，证明自己要靠行为，而不是谈钱。“
李嘉诚也说过：”让别人敬佩你的人品而不是你的钱，做人最要紧的是让人由衷地喜欢你，敬佩你本人，这些靠的不是你的财力，也不是表面上让人听你的。“
尽管我们都能大致这两位富豪财产数量级到底有多高，但我们最感兴趣的还是他们为什么能赚这么多钱，赚钱的方式是什么。他们财富的数字对我们意义不大，也没有任何好处。同样的，在任何地方你告诉别人你有多富有或多贫穷也没有任何好处，甚至会带来副作用。夸大自己的财富的数字除了满足虚荣心的外没有任何好处，骗子经常使用这一招让别人相信自己是个有信用的人。所以你应该像对待你的同事一样，向亲戚隐瞒自己的收入，甚至要避免向家人泄露，以免他们告诉别人对你回家造成困扰。我们要向李嘉诚和吉姆罗杰斯学习，靠自己的行为去获取他人由衷的敬佩，赢得他人尊重。
三、想尽一切办法避免攀比 我们上一代人从物质极度匮乏的状态中走过来。他们为了基本生活几乎付出了全部精力，在基本生活之外获取的收益让他们非常容易感到自喜。在农村攀比现象无处不在，房子，车子，工作，收入，几乎没有什么不能拿出来攀比的。在法律制度不健全，个人利益无法寻求合理保护的情况下，这种让别人觉得自己很强大是保护自己的的一种方式，也是一种竞争的方式，但这种面子上的争夺对你的实际利益毫无帮助，甚至有害。因为你竞争的战场不在面子，不在于别人的评价，而在于你自己做的事情。
四、保持良好的信用 吉姆罗杰斯说：“借钱一定要提前还，至少要按时还。好的信用至关重要，坏的信用记录会困扰你许多年。“
在我们那边的农村过年一般是提前一天过年，在大年二十九那天晚上吃年夜饭。我一直很疑惑为什么会这样，后来一打听才知道原来是以前留下来的习俗。以前人们为了防止债主大年三十追债，会提前一天过完年，然后三十那一天出去躲债主，新年初一那天债主也一般不会上门来追债。神奇的是这种非强制性的习俗两方都在遵守，我不只一次看到农村里面追债的全是三十那天上门，二十九和初一就不上门追债，然后欠债还不起的会像约定好的一样三十那天不会呆在家里等着别人上门追债。
这里面追债和还债的或许都透露出一丝无奈，也从侧面反应出信用不好所带来的影响，它甚至强大到能改变社会的习俗。现在虽然借钱方便了许多，可以从网贷平台借，不用再找熟悉的人借。但“债”的力量过于强大，最好的方式是量入为出，尽量不要负债。不然被人找到家里追债的滋味，无论任何时候都不好受。
五、节俭 农村里面到处存在着铺张浪费。从吃的到用的再到住的，浪费的无处现象无处不在。农村里面由于交通不便，无法享受到现代电商为生活带来的便利。人们要买东西不得不就近在镇上或县城买，这里面的东西几乎是劣质的代名词。你很难在小县城小镇上买到高质量的东西，优质商家无法把服务做到这里，人口居住的分散和交通不便导致服务的成本高昂。能生存下来的商家全是卖高利润劣质商品，它们非常难用，质量也不可靠，经常要换新。劣质商品造成的浪费非常高昂。而高质量的商品不仅耐用，而且残存价值高。
在吃的方面，农村过年全是大鱼大肉，蛋白质严重过剩，我们一顿能消耗的食物是有限的。我不知道过年在朋友圈晒年夜饭照片的人家他们是如何处理吃不完的剩菜。我每年过年回家父母准备年夜饭非常辛苦，吃不完的剩菜扔掉可惜只能继续凑合着吃。做这样吃力没多少好处的事情仅仅是因为我们需要过年，它对于我们来说非常重要，简朴一点的过年简直无法想象，会认为这样做没有“年味”。但认真的仔细想想简单一点过会有什么坏处呢？
住的房子越大越会影响居住的舒适程度，小房子在建筑成本和装修成本上更容易控制，就舒适度来说小房子更温馨。如果居住的房子小一点你会考虑用具的舒适性和质量，会自然而然的把没用或不好用的东西扔掉，而不是随意的放在房子的某个角落吃灰。欧美国家和日本很早就意识到了一点，他们乡下的房子都是矮矮小小的，房子周边的环境打理得非常干净。反观我们那边农村大家都在抢着盖大面积的高楼，大家宁肯多占点空地，多盖几间不住的房子，也不愿意多花点钱装修。大家都不太关心公共区域的修建，导致房前屋后都很脏，泥土经常会带进家里影响卫生。再加上建房没有像城市那样进行区域性的规划，公共设施几乎没有，这样的环境要保持干净整洁需要花费的功夫可想而知道。所以大家干脆就什么也不管了，就那样凑合着住。
美国的一些富人他们在财务自由后依然过着很简朴的生活，铺张浪费损失的不仅仅是金钱，而且还会损失一个人的时间和注意力，这两样东西金钱是无法换来的。遵循简单，朴素的生活不是一件容易的事情，它需要我们割舍一些不必要的东西。在工业设计里面，砍掉一个实体比增加一个要更费心思。长期保持简单，朴素的生活可以让人更加专注于收益的获取。
六、不做道德批判 我们理解一个人的行为最好基于事实出发，而不是他本人的是否好人或坏人，或者他做的是不是好事。好和坏这两个评判标准本身就很模糊，法律也只规定一个人什么事能做，什么事不能做，并不能判定一个人好或坏。当我们说某人很坏或很好时就要注意了，这时我们是基于道德判断而非理性判断。当我们走到一个地方时看到一些人做着不那么合规的事情时，这时不要急于去批判他们。每个地方的人道德准则的约束都不一样，我们内心道德准则对于他人来说是无效的，我们只能让道德准则运行在我们自己头脑之中，约束我们自己的行为。 如果能告诉当事人这样做不好并可以说服他们不要再继续做，那是再好不过的。但经过我的一些观察，事实上他们自己也知道这样做不好，但他们既然做了，就很难说服他们放弃继续做。
我们经济发展的这些年，农村物质的变化非常快，精神层面和人们的观念变化依然很慢。物质的变化可以快速用金钱换来，观念的变化非常难以改变，它需要几代人不断进步，以良好的教育为基础，这是农村最缺乏的。农村里面固然有很多不好的地方，既然短时间改变不了，就接纳所有的一切，包括好的和不好的，尊重他们的生活习惯，真正的认识这个世界。接纳并不意味着自己也要按照某种不好的方式生活，而是与他们和谐共处。
这些策略来自一些大师的智慧。谦虚，节俭这样的普世智慧在任何社会都是通用的。
延伸阅读：
《吉姆罗杰斯给女儿的18条建议》 － 吉姆罗杰斯
《富兰克林自传》 － 富兰克林
《见识》 － 吴军</description>
    </item>
    
    <item>
      <title>简单逻辑学</title>
      <link>http://www.leyafo.com/post/2018-01-17-simple-logical/</link>
      <pubDate>Wed, 17 Jan 2018 17:48:31 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2018-01-17-simple-logical/</guid>
      <description>There are two ways of thinking. One is to draw conclusions from your observations, and the other is proceed solely on the basis of logic.
​ Jim Rogers &amp;lt;A Gift to My Children&amp;gt;
 逻辑学是一门让思考变得清晰的学科，它是用来探寻事情的真相和本质。逻辑学在现代科学里面几乎无处不在，在国内外学术交流中，逻辑是交流双方的基本共识。逻辑还存在于语言的各个角落，语言本身就是使用逻辑构造的。我们用语言把大脑中的思考描绘出来，用逻辑在组织好这些语言，最后变成文章。本文就是使用逻辑来介绍逻辑学。
逻辑学的基本概念 第一性原则 (First Principles) First Principles 是一种思考方式，首先提出这个问题的是古时期哲学家亚里士多德。这种思维方式是从事物的本质出发，从最基础的地方衍生万千变化。古希腊不朽名著《几何原本》，从最基本五条定理出发推出一整个几何系统。现代物理学领域从世界上最小单位、不可再分的原子基础上构建整个科学体系。几乎所有科学领域都是从最本质的第一性原则(Frist Principles)出发构建整个科学体系。逻辑学也不例外。
我们来看看逻辑学的第一性原则
事物本质是什么？ 事物有存在和不存在两种状态，没有混合其中两者的可能性。 所有存在的事物，都有具体的原因。  以上三条我们归纳起来，逻辑的本质就是探寻事物的真相。
在生活中我们大脑容易过度关注事物的外在表现，而不是本质的东西。行李箱的发明是我们大脑关注错位的一个绝好的例子。在古罗马时期人们就需要携带食物做长途旅行，人们把食物放在箱子里由马车来运载移动。在后来的 1000 多年里，人们在箱子表面和材质上做各种改进，却没人想过把轮子和箱子结合起来。直到 1970 年一个叫 Bernard Sadow 的人在机场看到工人用一块镶嵌着轮子的木板在驼东西，带轮子的行李箱才在将近 1000 后，在偶然中发明。
First Principles 也是 Elon Musk 推崇的思考方式。去掉事物所有外在表现，从最本质的问题出发。在逻辑学里面推崇也是去掉事物的表面，关注事物本质。
三段论 古希腊时期亚里士多德提出著名的三段论，这是逻辑推理的基本过程。它是由证据(Evidence)间相互链接(Establish)，最终构成一个基本的论点(Argument)。以下是基本的三段论式的推理过程。
所有人都会死。 男人是人。 男人都会死。  我可以把它看成是法官断案，在综合(Establish)所有证据(Evidence)后，最终形成一个有效判定(Argument)。</description>
    </item>
    
    <item>
      <title>如何利用互联网学习？</title>
      <link>http://www.leyafo.com/post/2017-12-24-systemic-learning/</link>
      <pubDate>Sun, 24 Dec 2017 11:56:17 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-12-24-systemic-learning/</guid>
      <description>In this world we have two kinds of knowledge, one is Planck knowledge, the people who really know, they paid the dues they have the aptitude. Then we got chauffeur knowledge, they have learned to prattle the talk. They have a big head of hair, they have a fine temper in the voice, they make a hell of an impression, but in the end they&amp;rsquo;ve got chauffeur knowledge.
​ Charlie Munger</description>
    </item>
    
    <item>
      <title>go 语言操作数据库 CRUD</title>
      <link>http://www.leyafo.com/post/2017-09-07-go-db-crud/</link>
      <pubDate>Thu, 07 Sep 2017 15:37:42 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-09-07-go-db-crud/</guid>
      <description>go 语言标准库已经提供数据库访问通用接口，不同数据库需搭配相应连接 Driver。标准库里面 database/sql 实现基本数据类型 Scan, 基本的 Transaction 以及 sql 参数化。用这些东西去操作数据库完全够用，只是随着项目代码增长，sql string 会蔓延到项目的各个角落。若要修改数据库表结构，这些 sql string 就是噩梦一般存在。流行做法是使用 ORM(Object Relational Mapping) 去解决这个问题。ORM 封装好一些 CRUD 基本操作，可以避免大量手写 sql string.
go 编译型语言，无法做到像 Ruby 里面的 Method Missing 这样动态特性，可以为一个复合类型的 struct 随时添加一个 field. go 社区使用的 ORM 还是需要事先手动添加好 Field. 这样做需要对数据库和 struct 的成员做很多约定，写好对应的访问 tag。这些仍然无法避免修改数据库表时要一齐修改 go 代码。
我们可以仔细想想 ORM 真的是唯一的选择吗？ORM 实际上无法完美操作数据库，它做的事情无非就是这些事情：
 参数化 sql string。 封装一些简单的 CRUD 操作。 序列化 sql 查询结果。  对于一些复杂的数据库查询语句，任何强大的 ORM 库，灵活的动态语言特性都无法解决。况且 ORM 也未必是好东西，它简化了操作，却间接隐藏了数据库的一些功能。如果不脱离 ORM 依赖我们无法去更好的操作数据库，去自己优化查询语句。以 go 语言目前的特性来看，这个社区永远也不可能会做出能像动态语言那样灵活的 ORM。关于 ORM 与 go 语言更详细的吐槽请见这里。</description>
    </item>
    
    <item>
      <title>go 并发</title>
      <link>http://www.leyafo.com/post/2017-08-04-go-currency/</link>
      <pubDate>Fri, 04 Aug 2017 16:59:46 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-08-04-go-currency/</guid>
      <description>go 语言的并发非常简洁，只要写一个 goroutine 就可以了。
go func(){ println(&amp;#34;foo&amp;#34;) }() goroutine 会立即返回，这个匿名函数会并发执行。
如果需要和 goroutine 传递变量可以使用 go channels。从传递的角度来说，channels 可以分为发送和接收。使用 &amp;lt;- 符号作为传递，channel &amp;lt;- a 表示把变量 a 发送到 channel 里， &amp;lt;- channel 表示接收 channel 过来的数据。
从 channels 的属性角度来说，go channels 的类型分为两种：1.buffered channel. 2.Unbufered channel. 从字面上理解这两者的关系就是 buffer 和非 buffer，这个 buffer 可以理解为数组。如果只需要传递单个变量使用 unbuffered channel 就行了。
下面的代码是 unbufered channels 的传递
a := make(chan int) go func(){ a &amp;lt;- 1 }() println(&amp;lt;-a) //do another things unbufered channels 一个重要特点就是它是同步的，上面代码中 channel a 会一直等待到数据 1 发送过来才会继续往下执行。</description>
    </item>
    
    <item>
      <title>文档！文档！</title>
      <link>http://www.leyafo.com/post/2017-07-30-development-document/</link>
      <pubDate>Sun, 30 Jul 2017 18:29:44 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-07-30-development-document/</guid>
      <description>这个世界上会写字的应该要比会写代码的人多得多。但写点思路清晰的代码和写一份让人完全能读懂的文档都不是那么容易的事情。文档和代码这两件事情是相互影响的，鲜有见到文档写的好代码却写不好的事情，反过来如果一个项目文档写的很烂，那里面的代码肯定不会好到哪里去。
我现在由于所在行业的特殊性，需要和外面各种提供 API 服务的公司对接服务。这些提供 API 服务 90％ 的公司文档都写得有问题，没问题的那 10％ 是在行业做到顶尖的公司。
那些文档写得差的公司，不会意识好文档的价值。一份好得文档不仅仅是把问题定义清楚，它还会让项目的设计变得优良、规范。对于用户来说好的文档可以节约不少的时间，也能节约用户碰到问题时跑过来问你的时间。
下面以现在业界通用的 HTTP 协议为例，一份好的文档需要具备哪些基本的要素。
首先开发者自己必须要对 HTTP 协议烂熟于心，要完全按照标准返回 Head, Body, Response 这三要素。至于要不要完全用 Restful 标准，可以不用太在意，这不在本文的讨论范围内。
文档里面需要为每一个接口提供示例代码，世界上这么多语言你无法去为每种语言提供一份示例代码，那么就写个 curl 的调用示例好了（这就是为什么你必须要熟悉 HTTP 协议）。如果碰到那种不懂 HTTP 的开发者需要你提供一份他使用的语言的示例代码，你就让他去百度学习一下 HTTP 好了。
你的 API 里面少需要提供一个用来测试账号是否访问正常的就接口，因为这一块是在最容易出问题的。有了这样一个接口用户可以快速的排除掉这样的错误。
现在还有不少使用基于 HTTP 的 SOAP 做为向外界提供的接口。SOAP 这样的东西能丢掉就尽量丢掉，SOAP 是 Java 社区糟糕的产物。而且 XML 无论是对人对机器解析都很不友好，现在业界通行的做法是用 json。一旦定好一种数据格式就不要使用其他的格式（json 传文件可以使用 base64）。以免给用户带来额外的困惑。
我看到现在不少的 API 会有一些需要做 MD5 校验的操作，这样做是为了防止中间人攻击。这会给使用者带来额外的成本，这也是时代遗留产物，使用 HTTPS 根本就不会存在这个问题。
很多给企业提供的 API 方习惯了先商务洽谈，然后再提供相应的文档和账户。这里面存在的问题就是会有一个沟通传递的过程，这个过程中有可能会把文档忘记或丢失掉，并且文档一旦发给别人就无法修改了。既然使用了 HTTP，为何不把文档做为 HTML 直接输出到浏览器展现呢？一旦文档在线化了，更新就不是问题了。
文档里面的错别字就像吃饭时突然嚼到了沙子一样，会硌应一下。我的解决方法是不停的读，看到了错别字就马上修改，连续读三遍以上还没找到错别字就可以发布了。如果还有就继续改吧（在线化的好处！）。
对外提供的文档可以看出一个公司的很多问题，可以看出这家公司是否有做好一件事情的基本能力，可以看出他们自己对产品的重视程度。好的开发文档一个简单的标准就是就可以完全按照文档去做开发，并且不会有太多文档解释不了的问题。</description>
    </item>
    
    <item>
      <title>GUI 跨平台解决方案－2017</title>
      <link>http://www.leyafo.com/post/2017-07-18-cross-platform-gui-solution-2017/</link>
      <pubDate>Tue, 18 Jul 2017 20:27:13 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-07-18-cross-platform-gui-solution-2017/</guid>
      <description>这几天我想山寨一个 Notational Velocity。它的代码开源了，但年久失修。里面的 Objective-C 代码非常难读。Notational Velocity 我用起来非常舒服，我想让它能更通用一些，而不仅仅封闭在 Mac 平台。于是就打起了山寨它的主意。于是我便开始着手调研现在的跨平台 GUI 方案。
GUI 是客户端软件最基础，最必需的组件。现在 web 几乎统一了跨平台 GUI 解决方案。但如果你需要做与操作系统打交道的软件，你仍然无可避免的要去解决 GUI 跨平台的问题。 GUI 是阻止客户端软件跨平台最大的问题之一。这也是为什么现在为什么这么多软件全部 web 化的原因之一。
选择 web 做为 GUI 跨平台有如下好处： 1.用户不用安装软件，需要的时候拿来就用，用完即走。 2.开发者不用关心如何与不同操作系统交互的问题。 3.web 前端的学习成本非常低，适用性广。 4.web 现在的标准已经非常统一，很少会出现不兼容的情况。
web 本身是一种信息的组织方式，它通过 HTTP 协议把全世界的信息组织了起来。经过这么多年的发展它很偶然的渐渐变成了一种与用户直接交互的跨平台解决方案。web 这种典型的 C/S 架构是最适合 GUI 的，如果一个程序的 UI 不与其他部分分离，这个程序很快就会变得臃肿不堪（Linux xWindow 当年这么做还是有一定的道理）。只可惜这么多年了，操作系统的 UI 层一直未出现一个像 Chrome 这样统一的封装。但 web 另一大利器就是网络化，任何一个 web 应用不需要去做任何下载就能在浏览器里面使用，http 它统一网络 web 传输的协议。而平常操作系统程序都是基于本地的，即使有能做到像浏览器那样统一的封装，也无法做到像 web 这样遍布世界各地。互联网本质上就是信息的传播，而不是代码的传播，而 web 解决的问题刚好就符合了这一点。从这一点上来说，本地 GUI 程序和 Web 就不是一个层面的产物。浏览器相当于做出了一层统一的 GUI 接口的包装，有点类似于直接虚拟出了一层操作系统。web 就相当于运行在浏览器这一操作系统之内。由于安全性的问题，基于网络的 web 无法直接与操作系统打交道。</description>
    </item>
    
    <item>
      <title>我如何学习英语发音</title>
      <link>http://www.leyafo.com/post/2017-06-26-english-pronunciation/</link>
      <pubDate>Mon, 26 Jun 2017 13:04:06 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-06-26-english-pronunciation/</guid>
      <description>我们在学习英语时，平常用来说的机会并不多。毕竟我们身边都是使用我们第一母语的人在进行交流，一般人在条件允许的情况下是非常难以找到可以大量说英语的机会。在学校我们学习的英语是为应付考试，专业工作者（比如写代码）需要阅读大量的英文资料，这两个场景都是很少有需要开口说的机会。久而久之我们大部分人学习的英语都是哑巴英语。
哑巴英语的用起来问题并不大。但哑巴英语非常影响英语学习的，它会影响听力，影响对单词的记忆。我上学的时候老师没有系统的教过发音，音标这些东西。我多年来基本上也是哑巴英语，发音问题影响我在英语方面的进步。这是我最近系统的仔细去学发音后才发现的。哑巴英语会丧失在英语学习方面一个重要的维度。
英文发音和口音并不是一回事。我们很多人喜欢去嘲笑别人的发音带口音，实际上他们自己却很少把音发对。嘲笑别人的发音是非常不好的，这造成我们越来越多的人不敢开口说。害怕被嘲笑发音，口音，语法这些问题。我们很少去嘲笑一个儿童说话时奶声奶气，说话说不清楚。却喜欢嘲笑一个成年人一开始说外语说不标准。我们很多人学习外语这么多年后才发现（或者根本没意识到）我们说的外语其实就是和儿童在一个水平线上的。我们说这么多年中文，忽然换一个发音系统的语言，自带一点以前的口音是再正常不过。
产生口音的原因有两个：
我们碰到某个音不会发的时候，我们会无意中用母语发音的方式去发。
我们的语调带有母语的语调。
对于语调而产生的口音我个人觉得是很难扭转的。我们成年人多年形成的说话习惯很难一下子扭转成一门外语那样的说话方式。幸运的是语调并不会影响沟通，它顶多听起来没那么标准而已。但我们一开始目的并不是把自己训练成 native speaker 那样标准。一开始这么高要求我想大多数初学者都会被吓跑的，也完全没有必要。我认为单纯的让初学者追求像 native speaker 一样的流利和标准简直就是愚蠢。
而最影响沟通的实际上是我们不会发某一个音而使用母语的音去发。这也是口音问题的关键。好在这个问题我们可以通过训练自己去解决这个问题。办法非常简单，就是大量的重复。经过大量的重复后，再碰到这个音就会自然而然的发出对应的音。比如英语中 R 这个音是要把舌头往后卷的，th 这个音是要咬舌头或用舌头把两齿出气的地方堵塞住。这在我们中文里面是没有对应发音的。我们很容易就会把 R 发成 啊 ，把 th 发成 S，这就产生最根本的发音问题。很多人却误认为这是口音问题。
我本人就一直存在发音不会发而用母语音代替这个问题，我开始也以为这是口音问题。我这段时间大量的做发音训练才后知道原来这个问题真的能改善的，而且不需要太长的时间就能达到不错的效果。我的学习方法很简单，就是严格按照赖世雄的这个方法来操作的：”少就是多，慢就是快，不断重复“。我在网上找 Paul S. Gruber 的 15 集教程，每集大约 10 分钟左右。每集我大概会花 4 个小时的时间去不断的跟着读，模仿 Paul S. Gruber 的口型。有时碰到一些难发的音学习的时间还会更长。这 15 集的教程真的做得非常好，它不像以往的音标教程那样一个音标一个音标的教。而是把音标归类，把 ESL 人士容易发错的音重点列出来。也没有那些难以记忆的音标符号，它全部是对应真实单词中的音。
经过这段时间的训练后我很明显的感觉到进步。以前看到一个不认识的单词根本不知道该怎么发音，现在基本上能大概的读出来。现在对于发音这方面也更加自信，内心也不会有把某个单词读错的困扰。在平常的朗读训练中也能更好的去跟着录音读。我觉得最大的收获就是敏感度的增加。我现在能很明显的分辨单词拼写的一些细节，也能通过发音去拼写单词。在看英文视频的也能明显的感觉到敏感度的上升带来听力的提高。</description>
    </item>
    
    <item>
      <title>我需要什么样的笔记软件？</title>
      <link>http://www.leyafo.com/post/2017-06-21-whats-notebook-we-need/</link>
      <pubDate>Wed, 21 Jun 2017 14:10:54 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-06-21-whats-notebook-we-need/</guid>
      <description>现在笔记软件这块领域已经成了一片红海。大厂的软件有 OneNote，Evernote，Wiznote，有道等。类似功能的软件小厂出的现在也数不胜数。连苹果这种并不以软件见长的大厂都把他自家的 notes 加上了云同步的功能开始进入这片领域，可见一个笔记软件对用户的重要性。
我使用过 Evernote 和 Onenote 这两个笔记软件。这两个软件都有同样的问题，就是臃肿，同步慢。数据存储格式不开放，无法自己去管理数据。弃用这两个软件后，我开始尝试去使用各种各样的笔记软件。由于之前受够了大厂软件的臃肿不堪，我后来使用的这些软件都是一些很轻量的软件。这些软件都能做到想用了快速打开就能用，用完了马上就走这一特点。我用 Apple Notes 随时随地纪录各种各样的文字和一些零碎的想法。用 Notational Velocity 来写加密的私人日记。用 Ulysses 保存我写的一些文字。用 DropBox 备份好我自己生产的文字。用 Typora 写 markdown 文档。由于这些软件都比较轻量，都在我使用的这些方面做得很好。
我现在的问题在于我至今没有找到一款顺手的笔记软件能满足我上面用的这几个软件的功能。甚至找一个能达到 80％ 需求的软件都没有。我需要的一款能按照主题，按 tag 组织好我的笔记的软件，组织信息是第一位的功能。像其它类似加密，Markdown 编辑，这些功能都不是那么重要。我希望能做到，每次我需要找一些以前纪录过的笔记就能快速的检索到。按主题按 tag 分类信息的目的也是为了能快速的检索。纪录的数据文件格式要足够开放，我希望有一天如果这个软件不维护了，我将这些数据可以很方便的导入导出。格式开放的另一个好处就是我能随意的把数据加密后放到任意的云上。因为这些数据是隐私数据，我不希望明文存到任何公司的云上面。这个软件必须要跨平台，甚至能很方便的在移动设备上访问。
写到这里问题已经很清晰了，就是我需要的是一款信息组织工具。这个工具能让我很快的查找到我以往纪录的内容。并且这些数据必须是要我完全私有控制的。至于其它的功能我觉得我现在用的这些工具已经解决的很好了。所以我觉得个人搭建一套私有 wiki 系统是比较靠谱的选择。这个 wiki 系统最好是 web 形式呈现的，这样跨平台与移动设备访问的问题也就解决了。
现在我找到了一个符合我的这些要求的开源软件，这个软件就是 DokuWiki。它是一个基于 web 访问的软件，所有的内容都是以 txt 文本形式存储在服务端。为了简便它连数据库了也省了，内建索引可以快速搜索。由于开源，社区有海量的插件支持，代码也可以随意修改。安装也比较方便，把 host 地址指向 127.0.0.1 就能做为私人的笔记本使用了。无限制的的笔记 tag 和 category 对于管理资料很方便。所有数据都 host 在本地，没有任何第三方可以拿到数据，这正是我最需要的功能。由于是 web 形式的呈现，我可以把它 host 任何地方，手机也能访问。 现在唯一的问题就是它的内部的 wiki 文件格式是他自己特有的，我的一些笔记转换过来需要花点时间。不过这无所谓，把以往的笔记转为纯文本存储问题也不大。</description>
    </item>
    
    <item>
      <title>避开这 35 个坏习惯让你的代码可维护</title>
      <link>http://www.leyafo.com/post/2017-06-19-avoid-these-35-habits/</link>
      <pubDate>Mon, 19 Jun 2017 11:27:06 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-06-19-avoid-these-35-habits/</guid>
      <description>本文翻译自Avoid these 35 habits that lead to unmaintainable code
坏习惯难以改变，它会以意想不到的方式影响你的工作。如果你只是知道这些习惯，但并不在乎它，事情将会变得更糟。你既然来读这篇文章了，我想你肯定是在意这些坏习惯的。
作为一个程序员，我见过很多不好的开发方式。这不仅体现在代码方面，还体现在团队协作方面。这 35 个习惯都是我本人的一些坏习惯，我并不以此为荣。我将按照代码组织、团队协作、编码、测试、维护这些类别来描述这些坏习惯。
代码组织 1. “我承诺修复这个问题”，实际却永远也不去做。 延后修复这个坏习惯不仅仅只是一个定义问题的优先级。追踪一个问题需要耗费一些进度，但你仍然需要组织好问题追踪过程中的小问题。并在代码里面加上 TODO 确保这些问题不会被遗忘掉。
2. 过度追求代码的简洁性 追求代码的 “优雅”，“简洁” 是程序员的常见特质。当你把一个 20 行的正则表达式简化成 2～3 行，这就像解谜一样有趣。不幸的是，这并没有让代码变得更有利于阅读。代码可读性好才是更重要的，你应该首先确保这一点，然后再考虑代码的 ”优雅“。
3. 毫无目的的优化 我们常常会做一些没有意义的优化。这就好比通过优化文件大小来提高网站的加载速度。但为何不直接用 gzip 压缩？优化 request 难道不更有效吗？把优化工作放到项目结束的时候做，因为一般情况下优化是没有必要的，没有必要的优化就是在浪费你的时间。
 过早的优化是万恶之源。
​ －Donald Knuth
 4. 不注重代码风格 如果我多年来一直在学习他人的代码， 最不需要了解的就是这个开发者的代码风格。或许没有经验的开发者很难看出代码风格带来的问题。但大多数时候风格问题将会使项目脱离正轨，从而带来雪崩一样的混乱。在细微处保持严格最佳实践，启用 lint 检查工具，这些将会让你从这些细节中结果出来， 从而去关心更重要的问题。
5. 掩埋错误 无论捕获还是忽略异常或者使用不报告错误的库，掩埋错误的方式有很多种。但如果这些错误其中一个优先级变得很高，修复比忽略它要难很多倍，尤其是在你无从下手的时候。简单一点的方式就是避开它，然后纪录下来以便以后追踪。
6. 命名没有包含足够的信息 命名很难，但有简单的方法可以让你的函数和变量命名合格。只要你在名字里面包含特定的信息，不要传递额外的信息，你的代码可以容易的让别人阅读。命名如此重要的原因在于它可以描述代码具体的作用。好的命名会让你更容易理解代码的作用，否则你需要花费更多的时间才能深入的了解代码的作用。
7. 忽略更好的实践方式 代码复查(Code review)，TDD，QA，自动部署这些业界优良实践，为不计其数的项目产生了价值。这也是为什么开发者的 blog 会经常提到这些东西。这方面有一本非常好的参考书 Making Software: What Really Works, and Why We Believe It.</description>
    </item>
    
    <item>
      <title>前后端分离实践</title>
      <link>http://www.leyafo.com/post/2017-03-19-divsion-back-and-frond-end/</link>
      <pubDate>Sun, 19 Mar 2017 17:39:43 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2017-03-19-divsion-back-and-frond-end/</guid>
      <description>我们产品以前用的 Framework 是 Rails。Rails 有诸多好处，ActiveRecord 对数据库访问非常友好，各类 Gem 使用起来非常方便，新开一个项目无需过多调研就能立马做出一个看起来像那么回事的产品。这些好处显而易见对新手非常有利，可以克服开发过程中前期徒峭的学习过程。
Rails 可以很快的解决各类繁琐的业务逻辑，这都是基于 ruby 这门语言编程效率高。开发高效随之带来的代价就是运行效率低，效率问题只会在大规模用户量才会突显（参见 twitter）。在做产品的过程中解决复杂业务逻辑的效率取决于程序员对业务的理解程度，足够透彻的理解自然就会浮现简单的实现方案。从这个角度来说，业务逻辑与编程语言联系没有那么紧密，处理业务逻辑应该更多的去设计架构。
在 Rails 火爆的的年代，刚好是前端发展起步的年代。那个时候前端几乎只有 jQuery，那时做网页最快的就是使用 Rails 了。Rails 应该是那时前后端结合得最好的 Framework 了。Rails 的特点就是弱化前端，让后端的程序员顺带把前端的事情也干了，由此就产生 Full Stack Programmer 这样一个称谓。这几年 web 前端发展突飞猛进，这得益于 Javascript 的灵活。Rails 在后端做肯定是无法赶上 Javascript 的灵活性。如果现在依然还坚持使用 Rails 这种重后端的架构，肯定是无法获取到前端这几年迸发出巨大的生产力。
前后端分离可以让架构变得更加灵活，后端提供数据库端访问的 API 实现上会变得很简单，前端的程序员可以更加专注于界面效果的实现。现在手机端的 HTML5 是天然的前后端分离，这也更加促使项目不得不去做分离前后端。我们最开始分离前后端还是带着以前的思维去做的，在不用考虑数据库操作的情况下，我们选用了 Sinatra 做为后端提供。最开始我们还着把整个网站的 js 压缩打包到一个文件里面，我们甚至还把每一个 ajax 放到 Sinatra 里面单独处理。后来的事实证明这些思维给我们带来了不少的麻烦。
我们选用了 Vue 做为前端库，一开始用 Vue 的时候没有考虑到为每个页面单独加载一份 js，直到出现问题了才不得不去研究它的打包渲染机制。Vue 官方推荐的是 webpack 做为压缩打包的工具。在没有深入接触前端的情况下 webpack 对于我们来说明显是过于复杂了。所以我当时采用了 requirejs 这个几年前没那么激进的方案。当初不用 webpack 还有一个原因是我认为我们会需要在后端处理很多复杂的请求，用 webpack 我们就不得不去用 nodejs。后来的事实证明 Vue 表现非常好，我们的业务逻辑全部放到了前端去做，后端的作用只剩下 session 的管理和 API 的转发。</description>
    </item>
    
    <item>
      <title>git 初级教程</title>
      <link>http://www.leyafo.com/post/2016-12-18-git-getting-started/</link>
      <pubDate>Tue, 20 Dec 2016 11:11:54 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2016-12-18-git-getting-started/</guid>
      <description>Introduce git 不是一个对新手友好的工具，大多数新手第一次面对 git 总会有点手无足措。这时当你开始怀疑是不是一个蠢货时请不要停止，继续保持怀疑。面对一大堆命令和魔法般的黑色 terminal 大多数新手都会手无足措，不知道该怎么去用 git 去提交自己的代码。更可怕的事情是，如果搞砸了还会导致你旁边的豹子头同事把你给撕了的危险。本文档的主要作用是就是可以让你顺利的把代码提交到 git 库，避免产生意外的人身伤害。
Example 在被我忽悠 git 后你可能会偷偷的跑去网上找 git 相关的教程读。或者在看到我贱指如飞、神乎奇技地在键盘上狂按一通的时候你偷偷的拿笔在旁边记录我敲过的顺序。作为一个踏坑无数，身经百战的老司机有必要在这时告诉你一点儿人生经验，你这么做并没有什么卵用！！！因为你碰到的问题和网上那些教程说的是不一样的，老司机和你看到的世界也是不一样的（隔壁老王用的撩妹技能你直接拿去用会有什么后果？）。因此我们现在以平常工作中最简单的一个应用场景来解释 git 的基本用法。
现在假设有两个农民工张大锤，王大锤，以下简称老张和老王。老张和老王每天搬砖太累了，他们决定写一部电影剧本来改变世界。但两个人在同一个剧情时间点上写同一件事情的时候总是会产生冲突。老张本来在 1970 年10月24日把男主角写挂了。但老王由于刚在淘宝买了块机械键盘，打字打得太爽了。在1970年10月24日这一天写成男主角正在吃着火锅唱着歌。这个时候冲突产生了，老王和老张为了这个事情从相亲相爱变成了砖角遇到爱。下面我们开始详细描述这一起恶性暴力的流血事件。
Commit 张大锤和王大锤已经写好了一些剧情了。他们的最开始的共同成果如下：
1	从前有个人，名字叫赵铁柱。他人长得帅，又多金，还会写代码。 最前面那个 1 表示第一行。
老张刚和前女友分手，伤心难过，悲痛欲绝，以致于影响了日常严肃文学创作。所以他把接下来的剧本改成了这样：
1	从前有个人，名字叫赵铁柱。他人长得帅，又多金，还会写代码。 2	后来他死了。 写完后老张开始提交代码，他先输入 git status 查看 git 库给出的文件改动信息。(git status 是一个人畜无害的命令，你敲破桌子也不会有人理你)。
[老张]$ git status On branch master Your branch is up-to-date with &amp;#39;origin/master&amp;#39;. Changes not staged for commit: (use &amp;#34;git add &amp;lt;file&amp;gt;...&amp;#34; to update what will be committed) (use &amp;#34;git checkout -- &amp;lt;file&amp;gt;.</description>
    </item>
    
    <item>
      <title>我看奥运会</title>
      <link>http://www.leyafo.com/post/2016-08-14-my-thought-about-olympics/</link>
      <pubDate>Sun, 14 Aug 2016 12:10:03 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2016-08-14-my-thought-about-olympics/</guid>
      <description>a blatant attempt to influence your music taste.
 今天早上看到关于中国游泳选手尿检阳性的消息。我当时的感受就是：”干得漂亮！最好能彻底查一查那些患有心脏病的选手到底是怎么回事“。有人说你这不爱国。我想说，现在的年轻人啊，你可以去爱生活，爱你身边的人，爱这个世界，为什么偏偏要做爱国这么 low 的事情呢？奥运会拿的那几块牌子对你的生活有任何影响吗？你跟着瞎起哄还上升到民族大义，傻不傻？
我个人有记忆以来大概是从 2000 年开始看奥运会的。这么多年过去了，我仍然没觉得这个运动会有多好看。 2008 我们举全国之力举办的那次我也没觉得有多好看。我个人最喜欢的一届是 2012 年的伦敦奥运会，因为开幕式和闭幕式有我喜欢的英伦摇滚演出。奥运会其实只是一个体育界的演出而已，国家荣誉只是媒体灌输给我们的观念。奥运会给我们的生活带来不了任何的变化。想想看中国参加奥运会这么多年了，我们国民的身体素质上升了多少？我们从小到大学校里像样的运动场有多少？我们平常会的运动除了跑步还有哪些？ 为什么跳广场舞的大妈越来越多？
这些问题的存在无时无刻不在提醒着我们是一个在运动和国民身体素质都很弱的国家。我们从小到大的学校不仅仅没有像样的运动场所，连像样的的体育老师也没有，甚至连体育课的都要被其他课程抢走。奥运会上表演的那些项目大部分在我们平常的生活里面是消失掉的。这些消失掉的项目大部分并不是因为门槛有多高，有多么的专业。而是因为我们真的没地方玩，没有人教过我们怎么去安全的去玩。在学校里面我们有少量的运动设施，还可以找到一些一起运动的同学。工作后我们连找个地方做跑步这样简单的运动都不是那么容易，还要担心下雾霾对我们的影响。中国自己参加和举办的各种运动会搞的如火如荼，而我们大部分人都没有学会去怎样运动，学会去怎样锻炼出一个强健的体魄。
奥运会是个很好的活动，让各类运动高手同台竞技，给我们普通人带来观赏性的同时也让我们由衷的赞美运动员那强健的体魄。顶级运动员经过日复一日的训练，达到完美动作给我们普通人带来了非常好的示范性榜样。但现在，我们在看奥运会到底是在看什么？是在看娱乐表演？还是在看脸、看腹肌？游泳这种的这么平常的运动每年我们都要淹死多少人？我们有多少人到了 20 岁甚至连游泳都不会？国家积极参与奥运这么多年，从来就没有想过向普通大众去推广这些运动。举国体制办的奥运会让那么一小部分人每天像牛耕地一样训练，最开始用鞭子抽，后来发现用鞭子抽不动了，牛的速度上不去了，这时便开始往牛的屁股上注射药物。运动竞技理想的状态应该是让喜欢运动的人去做他最擅长的事情，配合各种等级的联赛让不同级别水平有一个公平竞技的机会。顶级的运动员像走台阶一样一级一级的走到最顶级联赛上去。我们现在根本就没有这种联赛机制。好不容易搞了个比赛，我们却经常能听到高中生通过改年龄去和初中生打比赛的例子。这就导致了我们陪养出来的运动员没有经历过次级联赛，直接往顶级联赛上跑，比赛时却发现没有那么多比赛经验。这时候用药显然是个比较好的捷径，因为一开始他们就是走捷径的，在再往前走一步又何妨。
在动物世界里面狮子捕捉猎物的那种冲击力与爆发力非常炫目，还有猎豹全速冲击时身上的肌肉随风一样飘荡，这是大自然带给我们的美。足球场上运动员在场上奔跑，刘翔飞跃跨栏，短跑运动员发令枪响时冲击的那一瞬间，这些画面都很美，都是人类在展示大自然给我们的美。我们见过无数运动员泪洒赛场，为了这块奖牌付出的努力有多少是自己真正想要的呢？奥运冠军退休后乞讨，贫苦山区孩子为了生活而当运动员，这种苦大仇深的故事我们听过的已经太多了。每次一想到这些，我再看奥运会我就觉得特别糟心。我更愿意去看经常熬夜通宵面容憔悴的网吧少年打电竞，至少那里有很大一部分人是真正喜欢做这个事情的。那些迫不得已注射药物的运动员有几个是真正喜欢这个运动，享受比赛的？我们真的不需要那么多中看不中用的牌子，把运动还给我们普通大众，让喜欢运动的人去做运动员，少几个泪洒赛场苦大仇深的运动员，多几个洪荒少女，这才是我们需要的。
关于运动本身 我个人因为在两年前身体上的一些小毛病在机缘巧合的情况下开始去健身房健身。我个人并不是太喜欢在健身时的那种感觉，那种运动的感觉让人不那么舒适，很吃力，我喜欢健身完之后的那种感觉。这就好比你顶着巨大的压力前行，等去掉这些压力以后再继续前行，你会觉得很轻松，觉得自己又变强壮了，那种强壮的感觉真的很好。我从小到大从来没有踢过足球，到工作后才和同事踢过几次小场地足球。我这种烂水平在场上摸不到几次球，甚至有时要被派去当守门员。尽管如此，我仍然很喜欢这个运动。十几个人在场上为了一只球到处追，到处跑。有时把球带到球门前，临门一脚打进去时肾上腺素飙升那种刺激的感觉真的很好，很难在平常的生活中找到那种感觉。这就是我现在对于运动的看法，我不知道其他喜欢运动的人有没有更高的境界，我很想知道。</description>
    </item>
    
    <item>
      <title>开发笔记(2) － 部署遇到的麻烦事儿</title>
      <link>http://www.leyafo.com/post/2016-08-05-deployment-as-chore/</link>
      <pubDate>Fri, 05 Aug 2016 11:25:19 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2016-08-05-deployment-as-chore/</guid>
      <description>我们现在用 Rails 做开发，线上的环境配置非常繁琐。到现在仍然没有找到一个可以快速 setup 一个 server 的解决方案。以下是我们在部署一个新的 server 时要做的一些麻烦事，我希望有一天能够在半小时内不用 ssh 登陆服务器就能把这些事情做好。
一、服务器 setup 我们现在全线使用阿里云来配置 qa, production, db, backup 这些环境。每次新拿到一个 vps，我们做的第一件事情就是配置 ssh，创建相关人员账户，设置 public key，关闭免密码登录。这一系列的动作我们使用了 chef 来做这件事情，基本上做到了一键设置。还有像一些 bash，hosts 文件配置，安装一些常用软件等着一些比较简单的事情 chef 也做得很好。但 chef 能做好的事情也仅仅只有这一些而已。一旦我们需要安装类似于 rvm，ruby，postgresql 这样配置比较复杂的软件时 chef 就完全不能胜任了。其中有很大一方面的原因是 chef 配置非常之复杂、繁琐。里面各种各样的依赖，和每个 node 之间相互不同的 attributes 很让人焦头烂额。每次修改配置的时间超过了 setup 一个 server 的时间。如果长时间不去维护里面的 cookbook，过一段后又要重新去翻文档配置。这就是 chef 的问题，它带来的问题比要解决的问题更多。
二、ruby 环境 setup 我们现在用的是 rvm + ruby 的组合来运行我们的 app。rvm 主要的作用是管理不同的 ruby 版本，这几乎是所有解释型语言的通病，需要有一个版本管理工具来管理不同版本的解释器。静下心来想一想，我们其实并不需要多个ruby 版本。尤其是在服务器的环境里面很难会容许不同版本的 ruby 共存这样复杂的情况。因此 rvm 最主要的功能实际上我们是不需要的。我们尝试过在 server 自己手动编译一个指定的版本，但这样带来的问题是安装 gem 包需要 sudo 权限。也尝试过更改 gem 所在目录的权限，但一些 gem 有可执行文件，需要放在系统的 bin 目录下，这也需要 sudo 权限，这个再更改 bin 的目录权限就不那么适合了。我们现在的解决方案是使用 rbenv，这个工具和 rvm 做一样的事情，但安装配置比 rvm 要简单很多。到这时我才发现 rvm 和 rbenv 这样的工具更重要的是解决 gem 包的存放问题。</description>
    </item>
    
    <item>
      <title>开发笔记(1) － Count 问题 </title>
      <link>http://www.leyafo.com/post/2016-07-13-development-notes-1-count-problems/</link>
      <pubDate>Wed, 13 Jul 2016 02:51:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2016-07-13-development-notes-1-count-problems/</guid>
      <description>我们现在的生产环境里面最大的表数据量大概是 1kw 左右。我们这里有一个页面是将这张表里面的数据以列表的方式呈现出来。这个列表的功能有：上一页/下一页、跳页、总数页、数据的总条目数。这是一个很常见的 web 列表拥有的功能，这一系列的功能在数据量 10w 以下工作得很好。超过 10w 后页面 load 就会变得很慢。慢的主要原因是每次刷新操作和跳页操作都会去 Count 整个表，而且是精确的 Count，算法的复杂度为 O(n)。这种方式对于经常需要使用列表页查看数据的用户是完全不可接受的。
我们开始着手优化这个问题。羊毛出在羊身上，我们用的是 Postgresql 的数据库，当然会想到使用 Postgres 的一些功能去做这个事情。很快我们在 Google 搜索到了 Postgresql 的 Count estimate 机制。它通过获取 pg_class 这张元表纪录的信息来得到一个表里面大致的数据量。这种方法非常快，速度可达到毫秒级。但它有以下缺点：1.无法精确统计（从 estimate 这个词的意思就能看出来） 2.只能获取整张表的大致数量，无法做 where 条件过滤。问题到这里似乎还是没有解决。
从程序开发的角度来看，这个问题最好的解决方式是使用一个变量用来保存表的 Count，每次插入删除时需要对这个 Count 变量进行 +1/-1 操作。这样每次需要获取的 Count 时算法复杂度就会降到 O(1)，但从整体上看这个问题其实根本没有得到解决。数据库里面一张大表在做 Insert/Remove 时本身已经很慢了，维护这个 Count 变量需要保证原子操作。这么做不仅非常麻烦，还会增加 Insert/Remove 的开销。这里是具体的做法。事情到这里已经很明显了，对于数据库精确的 Count，我们是没有办法开发出一种低于 O(n) 复杂度的算法。但这个问题真的无解了吗？
现在的问题焦点全部都集中在 Count 上面，这个问题看起来是只要 Count 的性能快了，就能解决这个问题。但上面已经说，我们是无法开发出低于 O(n) 复杂度的 Count 算法。1kw 的数据量 O(n) 是无论如何也快不到哪里去的。跳出这个点来看，我们最终要解决的问题是什么？这个 count 的精确数字对用户来说真的能重要到牺牲等待时间来获取吗？其实在这个功能里面我们只所以需要 Count 这个数字仅仅是在做分页时精确需要计算出有多少页，尾页的数字是多少。所以影响这个问题的关键根本不是用户的需求，而是我们在程序开发时所追求的精确。只需要把这个 count 数字去掉就可以了，这将会让列表的操作速度大大的提升。实际上搜索引擎就是这么干的。以 Google 搜索为例，我们在搜索引擎随便输入点东西进行搜索得到得结果是海量的，它只会告诉你“大约”得到多少个结果，结果页展示一页，你并不会知道尾页在哪里（也不需要知道）。</description>
    </item>
    
    <item>
      <title>关于测试</title>
      <link>http://www.leyafo.com/post/2016-05-16-about-test/</link>
      <pubDate>Mon, 16 May 2016 00:25:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2016-05-16-about-test/</guid>
      <description>在我做 C/C++ 开发时测试这个概念在这个圈子里不那么流行，这也有可能是 C/C++ 这类静态语言写 test 不是那么好写。 C/C++ 这类静态语言写 test code 光想一想也挺烦的。但这并不是因此就不写测试一个借口。我现在做的 Rails 项目一开始也认为写测试会拖慢项目进度的，后来实践下来发现测试能很好的维护项目的稳定，这实际上节约了不少时间。只要克服下一开始认为测试代码会增加的心智负担就好了。
我们也不必太需要去理会什么 TDD，BDD，DDD 等一类名词。这一类名词对写测试的帮助并不大，而且有害。把原来本来很简单的事情弄得很复杂。写测试关键是要简单，只有简单的测试代码才能测试简单的测试代码。恩，这个有点绕。意思就是代码必须要容易测试，不容易测试的代码要把它改成容易测试的代码。TDD 奉行的测试驱动开发在我看来是挺难做到的。因为有时候我自己都不知道这个代码写好后会变成什么样子。单纯的一个输入输出是很难决定代码中间所经历的一些过程。还有一个重要的点就是被测试代码粒度越小越好，越小意味着模块化程度越高，接口的定义也越干净，这是非常值得的。所以别管什么 BDD, TDD, DDD 这一类名词，尽管写测试代码好了，尽可能把测试覆盖面辐射到更广才是最重要的。
Rspec 的问题 Rspec 定义了测试的领域语言，他的目的是让非开发人员也能写测试。这个目的挺美好的，想想也挺美好的。实际上我们在项目中很难找到一个会去写测试的测试工程师。写 Rspec 这个东西没有一点开发能力还真搞不定。所以 Rspec 的让非开发人员写 test code 还是想想就好了，test code 还是得你自己来写，因为你对你自己写得模块是最清楚的。另外相对于 Rails 自带的测试框架 Rspec 解决的还是相同的问题。Rails 自带的测试框架已经挺好的了，模块化分析测试也很好的控制了测试的粒度。关键是它非常快，跑完所有的测试要同样数量的 Rspec 快很多。这很重要，Rspec 的性能很为人诟病，因为会增加对写 test code 的厌恶。一个简单的测试用例要跑 10 秒是很影响写代码的体验的。
测试的作用 改代码比写新的代码要烦，需要小心的应对以前的历史包袱，还要了解以前的工作机制是怎样的。所以，如果有一些现成的测试用例代码就能很好的应对这些问题。它能保证你不回对以前的代码产生副作用，并且在些测试代码阶段可以让你自己在代码层面对接口的合理性做更详细的检查。能让代码质量变得更高。在项目部署前跑一遍所有的测试用例可安心不少，尽管部署时出现的问题大多数集中在恶劣的服务器环境上。</description>
    </item>
    
    <item>
      <title>彻底理解 KMP算法</title>
      <link>http://www.leyafo.com/post/2014-11-14-a-thorough-understanding-of-kmp/</link>
      <pubDate>Fri, 14 Nov 2014 07:02:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-11-14-a-thorough-understanding-of-kmp/</guid>
      <description>KMP 算法是一种子串匹配算法。其特点在于匹配子串时利用已经匹配成功的部分子串来跳转到下一次能再次匹配的串。书上列举的一大堆公式看着很犯晕，网上各类码农博客里面用代码写的文章，让本来逻辑有点绕的 kmp 更加绕。就我最近看到的文章来说最清晰的就是阮一峰 和 详解KMP算法。这两辆篇文章解释的通俗易懂，也有一些不太明晰的地方。本文的目的是在于解释笔者本人在理解 kmp，及阅读这些资料时不明白的地方。 首先还是来看 kmp 匹配子串所使用的方法，下文中字符串“TEST ABCABCABCDEF” 表示要匹配的主串，字符串 &amp;ldquo;ABCABCDEF&amp;rdquo; 表示待匹配的子串。(用肉眼我们可以看到要匹配的子串的位置在最后的位置)。首先像暴力匹配一样我们把不匹配的字符串全部进行匹配并跳过。
TEST ABCABCABCDEF ABCABCDEF | |-------- 进入下一个位置进行匹配 ------&amp;gt; TEST ABCABCABCDEF ABCABCDEF | &amp;lt;----- 还是不匹配,继续往前走 ------| | | ......前面三个还是不匹配..... 这个时候我们待匹配的子串走到了‘TEST ’后面一个位置
TEST ABCABCABCDEF ABCABCDEF | |------ D 和 A 不匹配。 这个时候主串和子串出现了部分匹配的情况，这个时候我们的子串该如何前进继续匹配？目前能想到的方法就是按照暴力匹配的方式继续向前进一步。但本文的目的不在于讨论暴力匹配，所以这种方法被 Pass 掉。如果直接将子串移动到现在不匹配 D 的位置，这种方式会错过可能会匹配的子串。比如下面这种情况会错过可能会匹配的子串。
ABCABCDEFGHIJK -----&amp;gt; ABCABCDEFG ABCDEFG ABCDEFG 因此上面的移动是不合法的，算法会出现错误。从这里我们可以观察到合法的移动是将子串移动到 ABC 。这样我们就能再次匹配到 ABC，这也就是本文前面说的那句话，利用已经匹配成功的部分子串来跳转到下一次能再次匹配的串。现在问题是我们该如何在程序中得到这个正确的移动位置？首先我们先来观察已经匹配的部分匹配子串。
TEST ABCABCABCDEF ABCABCDEF | |---------&amp;gt;部分匹配子串 ABCABC 从这里我们可以看到 ABC 出现了两次，因此 ABC 是我们需要的再次匹配的串。但这个 ABC 是如何得到的？因此我们现在我们需要解决的问题有2个。 1. 找到再次匹配串。 2.</description>
    </item>
    
    <item>
      <title>理解红黑树</title>
      <link>http://www.leyafo.com/post/2014-10-27-a-red-black-tree-implementation/</link>
      <pubDate>Mon, 27 Oct 2014 11:27:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-10-27-a-red-black-tree-implementation/</guid>
      <description>红黑树是有序平衡 BST(binary search tree) 的一种，它于1978年由 Guibas 和 Sedgewick 发明。红黑树是2-3-4 树 的一种抽象表示。有趣的是现在大多数算法书关于红黑树都没有提到过 2-3-4 树。算法书上关于红黑树的讲解都是基于定理来实现红黑树。至于这些定理怎么来的，算法书却没有描述过。这就是为啥算法书上的红黑树难以理解，这是算法书的坑。所以要理解红黑树，理解 2-3-4树 是必不可少的一个过程。
2-3-4树 2-3-4树的基本性质 2-3-4树也是一种有序的平衡树，所有从 leaf 到 root 的 path 的高度都是相等的。每个节点可以容纳1到3个节点，可以有2到4个子节点。下面就是 2-3-4 树的3种类型。
B D F H K O / \ / | \ / \ / \ / \ A C B E G A I L Y 2树 3树 4树 类似于 BST，2-3-4对元素的排序是左小右大。不同的3树和4树的子节点会有中间大小的子节点。比如上图的3树中的 E 就比 D 大 比 F 小。4树中的 I 比 H 大，比 K 小。L 比 K 大，比 O 小。</description>
    </item>
    
    <item>
      <title>rails 注册登录</title>
      <link>http://www.leyafo.com/post/2014-07-24-rails-log/</link>
      <pubDate>Thu, 24 Jul 2014 08:53:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-07-24-rails-log/</guid>
      <description>这几天在做一个小型的论坛，做到了注册登录这一块。之前没有完整做过注册登录这个东西，这次我打算从头写到尾去详细的了解里面的一些基本原理。所以这次并没有使用devise这样的 *gem*。
密码存储 用户密码安全存储是作为一个 web 开发者的基本节操。好在现有的一些解决方案已经能比较好的解决这个问题了，做起来也比较容易。只需要了解一些基本的安全常识就可以保证90%的情况下是安全的。 在数据库里面存储加密后的密文是为了防止被拖库，如果黑客拖下了整个用户表，加密后的密码他们拿着也是没有用的。即使是网站的管理员也是没法知道这个密码的真实原文。因为现在一般的密码 hash 算法是不可逆的。所以现在的一些比较常用的密码明文获取方式是进行字典暴力破解。如果在密码原文 hash 前给密码添加一些比较长的唯一的随机字符串，这会使攻击者的字典基本上失效(因为很长，枚举次数要上升很大一个数量级)。这就是密码加盐(salt)的基本作用。当然加盐的另外一个作用是让两个相同的密码产生不同的 hash 值。这样即使知道加密算法和加密后的密文也无法通过比较密文来得到原文。 在用户登录时我们会拿到用户的原始密码，这个原始密码相当于一把钥匙。拿着这个密码通过加密算法和数据库里面的 salt 得到加密后的密文。再用这串密文与数据库的密文进行比对，比对成功后则验证通过。在这样一个过程中，密码看起来就像打开箱子的钥匙一样，由用户携带，网站不进行存储。
session 和 cookie cookie 是存储在用户浏览器中的一段唯一标识，http request 会将它传送到服务端。现在一般的 web framework 会去检测用户的 http request 是否带有 cookie, 如果没有发现请求中没有 *cookie*，它会建立一个*session*。并且以 cookie 作为 key 来保存 *session*。这样如果用户下次同样 cookie 的 http request 进来了，就可以找到相同的 *session*。 session 和 cookie 是实现记住用户的基石。http 协议是无状态的协议。在用户登录某一个网站后，我们是需要记住登录状态的。这时候就要通过 cookie 和 session 来干这件事情。 rails 默认是已经将 session 建立好了。在 controller 中可以很方便的拿到 session 变量去存储一些信息。另外比较有意思的是 rails 默认是将 session 经过加密后存储在用户 cookie 中的。当用户的 cookie 传送到后端时会将 cookie 进行解密得到相应的 *session*。</description>
    </item>
    
    <item>
      <title>Capistrano 部署</title>
      <link>http://www.leyafo.com/post/2014-06-19-capistrano-deployment/</link>
      <pubDate>Thu, 19 Jun 2014 03:07:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-06-19-capistrano-deployment/</guid>
      <description>这几天要部署自己做的一个小板凳，是用 sinatra 写的一个简单的 blog 程序。这个程序很简单，代码非常少，可以像 php 那样直接使用 async 将代码。但我想熟悉下 Ruby 关于部署方面的技术，因此找到了 Capistrano 这个东西。Rails 的 web 后台对环境非常挑剔，Capistrano 是 Ruby 写的， 虽然它可以部署各种语言的代码，但可以部署 Rails 的程序不会太简单。
配置项含义 Capistrano 这个东西产生的一大堆配置文件有点让人迷糊。Capfile 相当于一个 makefile 文件，里面设置了一些任务是如何运行的。config目录下有三个配置文件，其中 deploy 子目录是用于配置部署不同的环境。默认的是 production 和 staging 环境配置项分别对应两个同名的文件。deploy.rb 这个文件相当于一个总配置文件，里面的是一些公共的配置项。
Capistrano 非常依赖版本控制，在 deploy.rb 文件中 repo_url 是用于设置代码仓库的地址的，配置好这个参数后需要确认服务器有访问代码仓库的权限。 scm 是设置具体的版本控制软件的。Capistrano 支持最好的是 git 和 svn。 deploy_to 是一个非常重要的参数，它指示了代码上传到服务器的具体位置,另外需要确保这个目录与配置好的用户名有足够的访问权限。这几个参数设置好后，其他的参数可以使用默认的了。然后再配置对应环境的具体配置项。 在环境配置项中，role 参数指示的三项分别是 app，web 和 db。这个三项分开的好处是可以让他们部署到不同的服务器上做负载均衡。单台服务器不用太关心，三项指向同一个地址即可。然后配置服务器的访问权限，配置非常简单，设置好用户名和 ssh public key就可以了。到这里基本的配置已经完成了，运行cap deploy:check 可以检测配置是否成功。这个时候如果 check 成功的话使用 cap deploy 命令就可以成功上传代码了。
让代码运行 代码上传后部署的任务已经完成了一小部分了，接下来就是具体的程序的启动与 http request的转发了。我使用的是 nginx + unicorn 组合来干这件事情的。首先要确保代码在本地能正常的运行起来，然后再去服务器上做进一步的测试。实际上更好的方式是所有的软件在本地的机器上能完全正常运行后，再将同样的配置文件上传至服务器。能避免不少因为不同机器，不同环境而引起的问题。这样服务器只负责运行软件，不做任何测试。这也是我最近所理解的生产环境。 首先来配置 unicorn 这个东西，一般的 web framework 都会自带 http 服务器用来做测试。自带的 http 服务器是不推荐直接跑在生产环境下的。nginx 更适合干这种事情，但 nginx 干的事情更加单一，它只负责将请求接收并转发。并不负责应用层的事情。unicorn就是这个应用层（php对应的是fastcgi），他负责将代码运行起来并与nginx进行通信。unicorn配置起来也非常的简单，在config.</description>
    </item>
    
    <item>
      <title>我认为PHP不好的地方</title>
      <link>http://www.leyafo.com/post/2014-05-22-i-think-php-is-terrible/</link>
      <pubDate>Thu, 22 May 2014 00:29:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-05-22-i-think-php-is-terrible/</guid>
      <description>最近在用PHP做项目，让我个人感觉PHP是门非常不顺手的编程语言。PHP太多东西给人的感觉就像是一个半成品。
namespace PHP 的 namespace 是我见过的所有语言最难用的 namespace，没有之一。它使用反斜杠\**来进行层级切分，在使用上非常容易跟 include 使用的文件路径斜杠搞混淆。namespace** 的 use 语句使用也是让人赶到非常奇怪，它不能在代码中的任意作用域使用，只能在一个文件的最顶级作用域中使用 use。namespace 这个东西是控制访问冲突使用的，在文件顶级作用域中使用 namespace 是一个产生冲突的隐患。这就是一个半成品，PHP 中的内部库函数是没有使用 namespace 的，也不知道他们自己为啥不用这玩意。
变量 在每一个变量前加一个$符号，让我对这个语言的第一印象非常不好，给我的感觉是丑陋。变量名加$可以很方便的嵌入到字符串中，但是 PHP 在字符串内嵌中增加了 {} 语法，这让变量前面 $ 符号失去了它唯一的作用。$ 符号除了让代码变得更丑陋以外，没有任何的实际用处。另外在 PHP 中 if 和 for 还有 while 一系列控制语句中，变量是没有作用域的。可以很随意的去拿 if 和 else 中的变量，解释器不会报错。但是你不知道什么时候解释器会给你报一个 undefine 的错误。
函数与闭包 函数本身没啥好说的，每个语言最基本的单元。如果这玩意也实现不好那真的太糟了。但我要说的是 PHP 从5.3以后引入的匿名函数。PHP 的匿名函数看起来好像是可以在任意的地方定义它，这很符合匿名函数的特性。但问题是你如果要用到上下文变量需要显示的使用 use 将变量引入。这看起来好像是没有什么问题，但是如果函数嵌套的层级一多，这完全是个枷锁。另外如果要判断一个变量是不是一个函数 PHP 有一个 is_callable 的方法,这个方法的奇怪之处在于你可以传入变量名或者以字符串形式传入函数名。但如果直接传入一个函数它返回的值是 false。经过使用 is_callable 函数的一些失败尝试后，我彻底放弃了 PHP 的匿名函数与闭包。</description>
    </item>
    
    <item>
      <title>avl 树的实现</title>
      <link>http://www.leyafo.com/post/2014-02-09-avl-tree-implementation/</link>
      <pubDate>Sun, 09 Feb 2014 07:01:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-02-09-avl-tree-implementation/</guid>
      <description>过年在家没事，找出了几年前把我折磨得死去活来的&amp;lt;数据结构与算法分析&amp;gt;这本书。确切的说，这段时间这本书也在折磨我。上面的avl树的旋转说得不清不楚的，而且还是使用递归实现了avl树的插入与删除操作。让这本书上本身就已经不太清晰的描述变得更加的扑朔迷离，让我有一种想烧掉这本书的冲动。到最后我实在没法看懂书上描述的avl树的操作方式只好自己从网上找一些资料实现了avl树(代码在此)。另外维基百科上有关于avl树基本性质的描述，我在这里也不过多介绍。但是请勿对照这篇文章去实现avl树，这篇描述的删除操作是有问题的。关于树的旋转，这篇文章也没有把最根本的问题说清楚。avl树最难的部分就是关于树的旋转，本文主要讨旋转的问题。
首先，旋转的作用是降低子树的高度。旋转的方式有两种，一种是用来降低左子树高度一般被称作右旋。一种是用来降低右子树高度一般被称为左旋。这两种旋转在物理上是对称的，在编码上也是无脑对称的。因此，在编码方面我们只需要实现出一种旋转后另一种旋转也可以依葫芦画瓢的实现出来。另外在每个节点中保存一个父节点可以让编码的复杂度大大降低。
下面是左旋的具体变化过程:
A B \ / \ B 左旋 ==&amp;gt; A C \ C  下面是右旋的具体变化过程:
A B / / \ B 右旋 ==&amp;gt; C A / C  上面的这两种情况是比较理想的情况，在实际的使用情况下是没有这么理想的。不能处理下面这些情况。
A A \ / B B / \ C C 上面的这两种情况就是书上所说的关于双旋转的问题。解决这两种情况的方法就是先旋转B节点,先将C点与B点旋转到A点与B点相同的指向方向。然后在根据A点做对应方向的旋转。
A A C A A C \ \ / \ / \ / \ B =&amp;gt; C =&amp;gt; A B B =&amp;gt; C =&amp;gt; A B / \ \ \ C B C B  写到这里貌似可以去开工写代码了，但是请等等。在实际的编码中碰到如下情况还是不知道到底该怎样旋转。</description>
    </item>
    
    <item>
      <title>我认为12306 可以改进的地方</title>
      <link>http://www.leyafo.com/post/2014-01-07-i-think-12306-areas-for-improvement/</link>
      <pubDate>Tue, 07 Jan 2014 10:10:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-01-07-i-think-12306-areas-for-improvement/</guid>
      <description>几条社会数据： 2013年春运期间卖出2.4亿张火车票，折半的话单趟就是1.2亿。 这1.2亿张火车票 网络售票数量不到4成 流动人口总数是2.2亿(不包括市辖区内人户分离)。 12306日每天2000万人访问点击量 高达14亿 最高日售票460万张
以上数据可以得出以下结论： 1.火车的运载量是不太够的。 2.实际网络买票人数员远大于12306售票数的总数。 3.12306卖出的票还是少了点。
下面是我认为12306可以改进的地方。
网页前端可以改进的地方： 我这几天也经历过几次买票，在高峰期进入网站后基本上是一个卡住不动的状态了。经过仔细观察12306的前端我发现改进的余地还是非常大的。
尽量静态化： 这么高访问量的网站必须要尽可能的减少客户端请求，网页前端能静态就静态。少设置一点图片，js与css可以参考rails的AssetsPipline 把所有的资源打包成一个文件，去掉不必要图片。这里可以参考奥巴马的选举网站。
页面功能单一化 访问量这么高，完全可以把网站所有不同功能的页面分开。订票与查询完全可以分开成两个页面，订票页面就不要再有其他的资源链接或者其它功能。
订票过程尽量简单 现在用户订票需要选择日期后再查询，然后服务器再返回好几趟车的数据。我认为这一步实在是很多余，买票的人这么多，大家都会事先查好需要买哪趟车，不会等到出票时间去查询再买。面对这种情况，最好是让用户直接再事前输入准确的车次，起终点站就可以了。这样就能减少服务器与客户端之间的数据传输次数与数据量。
可增加的功能（没错，我认为应该增加一些功能。） 现在的订票助手已经做到了离线化订票，既然这样12306为什么不直接把这件事给干了呢？12306拿到用户的订票信息，可根据偏远程度与火车的运载量在后台进行订票的优先级排序。甚至可以在某辆车运载量不够的情况下为用户自动安排最优化的换乘方案与对应的车票。
增加电话订票的可用度 不得不说电话订票实在太难用了，中间经历的过程非常烦琐。能用电话订到票的基本上需要一部带有机械键盘的座机与职业游戏玩家的反应与手速才能做到。简化电话订票中间的流程，多开通几个订票号码，这样能分流一部分订票压力。
后台改进 从春运的卖出的2.4亿张火车票的数量上来看，这真的是实实在在的大数据处理。甚至被称为世界级难题我认为都是可以的。因为后台跟12306前端所面对的问题完全是不再一个层面上的。因为后台需要将电话，售票点，代售点，网络售票，退票这几个点的火车票全部进行管理。也就是需要为这2.4亿张火车票做一个中心数据库系统。而且这个系统需要满足： 高并发：几百万人在一个时间点同时买票。 高可用性：不能done机 高响应：读写的时间不能太长 恐怖的一致性：是的，这个一致性很恐怖。因为所有的订票请求，都需要在一个地方去拿，不能出现两个人订到了同一张票的情况。虽然电话，售票点，代售点，退票这几个点可以提前分配好资源。网络售票在一个时间点保持几百万个资源的一致性是非常恐怖的操作。
改进方案： 陈皓在去年提出了几点解决方案：数据镜像 ，数据分区 ，后端系统负载均衡
他的大致思路是一个数据负载均衡的思路。就是尽量不让用户去大量的访问一个点。实际上铁道部已经在去年开始就使用了分时间段买票的方法。这一方法就是一个负载均衡的思路。效果是有了，但是实际上只是消化了一部分数据，但还是有海量的数据存在。我倒是比较赞同他的另外一个思路，就是收集用户的订单，然后到了一定的时间与数量再提交到中数据库中。
我的思路： 既然要批量提交，为什么不把剩余票源提前从数据库里面挖出来做一个缓存，然后读写这块缓存，到最后在提交这块缓存到中心数据库。每个节点服务一批用户，缓存的节点不能太少，缓存应该在从中心数据里挖出来的那时候起就要保证将来数据库里一致性的问题。但难度在于如何将用户分配到适合的票源缓存点去？这就要按车次与席别还有乘车日期类型的不同来分配车票的类型。这个计算过程是独立，完全可以很轻松的做到并行计算。
小结 春运火车票这个问题基本上无解，因为需要买票的人数大于票的总数。火车的载量是有限的，技术能解决的问题只能是让尽可能多人的人更顺利的买的票，不能产生更多的票。所以我想无论是叫阿里还是其他市场化的公司来做这个系统，没有买到票的人该骂的还是照样会骂。当然，上面的提出的一些方式也是比较理想化的。并没有过多的去考虑太多的细节问题。</description>
    </item>
    
    <item>
      <title>Rails 的 AJAX</title>
      <link>http://www.leyafo.com/post/2014-01-06-rails-ajax/</link>
      <pubDate>Mon, 06 Jan 2014 14:00:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2014-01-06-rails-ajax/</guid>
      <description>在 Rails 中只需要指定在 erb 模板中指定 remote=true 选项就可以将请求变为异步的了。request-handle-response-callback 这是一个 AJAX 请求的过程。rails 将这些步骤直接简化成了 request 和 handle 两步，让它看起来的像魔法一样而简洁神秘。在我初次接触 Rails 的 AJAX 时，我也随手去翻了下 wikipedia 关于 AJAX 的条目。AJAX 很好理解，但这并未让我更好的去完全理解 Rails 魔法般的 *AJAX*。主要被困惑的在 controller 的 handle 函数里面的 response 实现。
def handle @model = new some_model #do something if @model.save respond_to do |format| format.js end end  上面是一个典型的 Rails 应用场景，完全没有了那些简单粗暴原生的 html 与 javascript 的代码，更加别想看到 XMLHttpRequest 这种对象了。respond_to 是一个接收代码块的方法。而 format 表示 response 时使用的数据格式，format.js 会找到对应的 handle.js 并将里面的 js 代码 repond 到客户端。这仅仅只是客户端需要 js 类型回复的一个需求。如果客户端需要 json，XML，HTML 等不同类型的数据，只需要在 repondto 这个代码块使用 format 对象调用对应的方法即可。rails 会自动判断并回应对应的类型的数据到前台页面。 这样做的好处有： 1.</description>
    </item>
    
    <item>
      <title>vim 最佳实践</title>
      <link>http://www.leyafo.com/post/2013-11-26-the-best-practical-vim/</link>
      <pubDate>Tue, 26 Nov 2013 04:01:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2013-11-26-the-best-practical-vim/</guid>
      <description>重装你的vim 是的,重新安装你的 vim. 因为默认安装的 vim 是不带 python 和 lua,ruby,perl 这一系列脚本支持的.因此你需要加入这些脚本支持,然后重新编译安装.重新安装前请先备份好 ~/.vim 目录中的东西与 vimrc.
源码编译安装: 以 OSX 系统为例,在 vim 源码目录的 src 目录下有一个 configure 文件.运行 ./configure &amp;ndash;help 可以看到一些编译选项,从中添加你想要的编译选项.在添加 &amp;ndash;enable-pythoninterp 请一定要带上 &amp;ndash;with-python-config-dir 这个选项,用来指向你的 python config 目录.在 OSX 系统中这个值一般是: /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/config. 另外请勿使用 homebrew 安装的 python, 编译过程中会找不到 python frameworks. 如果配置有问题可以查看 src 目录中 auto/config.log 来看详细错误.编译成功后会在 src/macvim/build/release 目录生成好 dmg 安装包.
从homebrew中安装: homebrew 也是下载好源码然后编译安装的.在 brew install macvim 前,可以使用 brew edit macvim 来编辑一些编译选项.只需要在 args = %w[] 这个中括号里面添加 configure 中的编译选项. 编译中产生的错误日志可以在 ~/Library/Logs/Homebrew/macvim 目录下查看.</description>
    </item>
    
    <item>
      <title>尾递归优化</title>
      <link>http://www.leyafo.com/post/2013-11-23-tail-recursion-optimization/</link>
      <pubDate>Sat, 23 Nov 2013 11:47:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2013-11-23-tail-recursion-optimization/</guid>
      <description>递归是一个奇特的玩意,它能简洁的描述复杂的思考.
一个简单的递归函数:
def fibonacci(n): if n &amp;lt;= 1: return 1 return fibonacci(n-1) + fibonacci(n-2)  这个函数实现了一个裴波那契数列.非常简单,代码只有 3 行,但如果跟着函数运行的轨迹走.会发现这个函数背后的调用过程非常的复杂.每次递归都会依赖前面两次计算的结果.随着递归的层级上升,每次都会重新去调用前两次计算产生的结果.为了简化描述,下面是以 fibonacci(5) 模拟递归调用过程. 可以看到,每次递归都会重复前两次的调用过程.实际上这个递归数列并不需要每次都重复去求前两次的结果.如果用压栈的方法,一遍递归就可以搞定了.
def fibonacci(n): L = fibonacci.L if n &amp;lt;= 2: return L[-1] #get top else: n2 = L.pop() n1 = L.pop() L.append(n2) #&amp;#39;append&amp;#39; is stack&amp;#39;s push  L.append(n1+n2) return fibonacci(n-1) fibonacci.L = [1,1]  上面的代码耍了一个小花招.首先先设定好两个初始的计算结果,然后开始递归迭代.与前一版本递归不同的是,前一个递归需要在进入到递归底部后,才开始跳出来计算每一步递归后的结果,直到返回.而后一个递归会在最开始递归进入时就开始计算,进入到递归底部后(也就是 n &amp;lt;= 2)最终的结果就已经计算出来了,直接一层一层返回这个结果就可以了. 为了便于说明下面代码是利用两个变量做中间结果的版本:
def fib(n, n1=1, n2=1): if n &amp;lt; 2: return n1 return fib(n-1, n2, n1+n2)  跟上面那个压栈的方式一样.</description>
    </item>
    
    <item>
      <title>关于NoSQL</title>
      <link>http://www.leyafo.com/post/2013-11-14-on-nosql/</link>
      <pubDate>Thu, 14 Nov 2013 09:39:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2013-11-14-on-nosql/</guid>
      <description>传统关系型数据库,将数据以表结构的方式存储起来.并且所有的数据是基于 ACID1 原则.这种方式存储数据有很明显的缺点.首先,为了保证一致性,基于 ACID1 类型的数据库都是使用事物来保持数据的一致性.也就是说同时只能有一个 client 提交数据.然后,以表结构存储的数据库架构是死的,一个表的列基本上是固定的.如果变化的话会带来很多问题.
比如:
1.我有一种数据,这些数据都是一些 Excle 表格.每个表格的列都不相同.但实际上他们都是一种数据.该如何存储?
2.一个表有 10 列,我想再加一个字段,但这个字段并不是所有数据都需要的.
3.问题同上,如果加 20 个字段呢?再新建一个表?新建的表如何与现有的表关联?
最后关联性数据库还有个不利于分布的弱点,如果数据分布在 N 台分布式的机器上,数据库该如何管理?
为了弥补这些缺点, NoSQL 类数据库诞生了.首先 NoSQL 类数据库有以下特点:
schema-less: 数据没有字段的概念,并且数据仓库(关联型数据库的 table )可以随时变化字段.
Strong Consistency: 保证数据最终的一致性.
High Availability: 保证所有请求数据的客户端都能得到一份数据的 copy.
Partition-tolerance: 数据可以不限于分布在同一台机器上.
一般 NoSQL 类数据库存储数据的模型有 4 种方式:
Key-Value: 类似于 json 的 key-value 的方式进行数据存储
BigTable: 多维度的 key-value 结构,并且存储方式是分布式,稀疏的2,严格排序的. Google 很多产品都在用,具有高压缩,高性能,易于查询的特点.
Documents: 多个 key-value 结构的数据合为一条数据,每一条数据称为为一个 docment. 并且每个 docment 的 key-value 个数和 key 都可以不同.并且在搜索时,可以以 value 做为关键字来搜索.</description>
    </item>
    
    <item>
      <title>Python内存管理</title>
      <link>http://www.leyafo.com/post/2013-11-08-python-memory-management/</link>
      <pubDate>Fri, 08 Nov 2013 11:25:00 +0800</pubDate>
      
      <guid>http://www.leyafo.com/post/2013-11-08-python-memory-management/</guid>
      <description>本文基于Python2.7.5源码中的obmalloc.c模块
 在 Python 的内部系统中，它的内存管理结构是以金子塔结构呈现的.如下图所示:
- 其中-1和-2这两层是跟操作系统来负责的,这里我们略过不表.
- 第0层就是我们平常在 C 中使用的 malloc, Python 不会直接使用它,而是会在此基础上做一个内存池. - 第1层是 Python 自己在基于 malloc 的基础上构造的一个内存池. - 第2和第3层是基于第1层的.每当 Python 内部需要使用内存时,会使用第1层做好的分配器来分配内存. 因此第1层是 Python 内部管理内存的主要地方.
作用 在 C 中如果频繁的调用 malloc 与 free 时,是会产生性能问题的.再加上频繁的分配与释放小块的内存会产生内存碎片. Python 在这里主要干的工作有: 1. 如果请求分配的内存在1~256字节之间就使用自己的内存管理系统,否则直接使用 malloc. 2. 这里还是会调用 malloc 分配内存,但每次会分配一块大小为256k的大块内存. 3. 经由内存池登记的内存到最后还是会回收到内存池,并不会调用 C 的 free 释放掉.以便下次使用.
内存池结构 如上图所示,整个黑框格子代表内存池(usedpools).每个单元格存放一个双向链表,每个链表的节点是一个大小为4k的内存块.在这个池中,每个单元格负责管理不同的小块内存.为了便于管理,每个单元格管理的内存块总是以8的倍数为单位.以如下代码为例:
PyObject_Malloc(3) 这里我们需要一块大小为3个字节的内存.它将定位到管理大小为8字节的单元格.然后返回大小8字节的内存.在这里 usedpools 有一个令人蛋疼的 ticky. usedpools 在初始化时用了如下代码:
#define PTA(x) ((poolp )((uchar *)&amp;amp;(usedpools[2*(x)]) - 2*sizeof(block *))) #define PT(x) PTA(x), PTA(x) static poolp usedpools[2 * ((NB_SMALL_SIZE_CLASSES + 7) / 8) * 8] = { PT(0), PT(1), PT(2), PT(3), PT(4), PT(5), PT(6), PT(7) .</description>
    </item>
    
  </channel>
</rss>